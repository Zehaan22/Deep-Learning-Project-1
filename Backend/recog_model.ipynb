{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a few hyper parameters\n",
    "NUM_CLASSES = 10\n",
    "NUM_FEATURES = 900\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "The data files that we have are :\n",
    "1. X_data.pt:\n",
    "<br>\n",
    "    This file has the slate matrix data.\n",
    "\n",
    "2. y_data.pt:\n",
    "<br>\n",
    "    This file has the y labels for all the slates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the necessities \n",
    "import torch\n",
    "\n",
    "X_data = torch.load('../X_data.pt').numpy()\n",
    "y_data = torch.load('../y_data.pt').numpy()\n",
    "\n",
    "X_data[:5],y_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the train and test split\n",
    "\n",
    "train and test split ration is 80-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([3, 0, 7, 5, 6]))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data,\n",
    "    y_data,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "X_train[:5],y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Classification Model\n",
    "Our model taken in 900 input points as a matrix, and classifies the matrix into 10 digits.\n",
    "\n",
    "* <code> in_features </code> : 900\n",
    "* <code> out_features </code> : 10\n",
    "\n",
    "We will have 2 hidden layers with 16 features each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nn\n",
    "from torch import nn\n",
    "\n",
    "class DigitModel(nn.Module):\n",
    "    \"\"\"This is the multiclass classification model for matrix to digits.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features = 900):\n",
    "        \"\"\"Create an instance of the model.\"\"\"\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=in_features,\n",
    "                out_features=16\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(\n",
    "                in_features=16,\n",
    "                out_features=16\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(\n",
    "                in_features=16,\n",
    "                out_features=10\n",
    "            )     \n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear_stack(x)\n",
    "    \n",
    "    def logits_to_preds(self,logits):\n",
    "        \"\"\"Convert Logits to predictions.\"\"\"\n",
    "        probs = torch.softmax(logits,\n",
    "                              dim=1)\n",
    "        preds = torch.argmax(probs,\n",
    "                             dim=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing the model\n",
    "\n",
    "We create an instance of the hindi model\n",
    "Define the loss function : <code>Entropy Loss</code>\n",
    "<br>\n",
    "Define the grad fucntion : <code>Stochastic Gradient Descent</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1076e2e70>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an instance of the hindi model\n",
    "hindi_model = DigitModel()\n",
    "\n",
    "# Creating the loss function \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Creating the grad fucntion\n",
    "optimiser = torch.optim.SGD(\n",
    "    hindi_model.parameters(),\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "# Epoch Count \n",
    "EPOCHS =int(1e3)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tesnoring the data\n",
    "X_train = torch.tensor(X_train).type(torch.float)\n",
    "X_test = torch.tensor(X_test).type(torch.float)\n",
    "y_train = torch.tensor(y_train).type(torch.float)\n",
    "y_test = torch.tensor(y_test).type(torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2741, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo_list = [0]*10\n",
    "foo_list[int(y_train[0])] = 1\n",
    "foo_list = torch.tensor(foo_list)\n",
    "\n",
    "inp = hindi_model(X_train[0])\n",
    "inp = torch.softmax(inp,dim=0)\n",
    "\n",
    "\n",
    "loss_fn(inp,y_train[0].type(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 10.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 20.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 30.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 40.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 50.00, Loss: 2.32, test_loss: 2.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 70.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 80.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 90.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 100.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 110.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 120.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 130.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 140.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 150.00, Loss: 2.32, test_loss: 2.26\n",
      "Epoch: 160.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 170.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 180.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 190.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 200.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 210.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 220.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 230.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 240.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 250.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 260.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 270.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 280.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 290.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 300.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 310.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 320.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 330.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 340.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 350.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 360.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 370.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 380.00, Loss: 2.31, test_loss: 2.26\n",
      "Epoch: 390.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 400.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 410.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 420.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 430.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 440.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 450.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 460.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 470.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 480.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 490.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 500.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 510.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 520.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 530.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 540.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 550.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 560.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 570.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 580.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 590.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 600.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 610.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 620.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 630.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 640.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 650.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 660.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 670.00, Loss: 2.30, test_loss: 2.26\n",
      "Epoch: 680.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 690.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 700.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 710.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 720.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 730.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 740.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 750.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 760.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 770.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 780.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 790.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 800.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 810.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 820.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 830.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 840.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 850.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 860.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 870.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 880.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 890.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 900.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 910.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 920.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 930.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 940.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 950.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 960.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 970.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 980.00, Loss: 2.29, test_loss: 2.26\n",
      "Epoch: 990.00, Loss: 2.29, test_loss: 2.26\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# training and testing loop\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training part\n",
    "    hindi_model.train()\n",
    "    \n",
    "    y_logits = hindi_model(X_train)\n",
    "    y_probs = torch.softmax(y_logits,dim=1)\n",
    "    y_preds = hindi_model.logits_to_preds(y_logits)\n",
    "    \n",
    "    '''foo_train = []    \n",
    "    for i in y_train:\n",
    "        foo_list = [0]*10\n",
    "        foo_list[int(i)] = 1\n",
    "        foo_train.append(foo_list)\n",
    "    foo_train = torch.tensor(foo_train).type(torch.float)'''\n",
    "    \n",
    "    loss = loss_fn(\n",
    "        y_logits,\n",
    "        y_train.type(torch.long)\n",
    "    )\n",
    "    \n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # Testing code\n",
    "    hindi_model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        y_logits = hindi_model(X_test)\n",
    "        y_probs = torch.softmax(y_logits,dim=1)\n",
    "        y_preds = hindi_model.logits_to_preds(y_logits)\n",
    "        '''foo_test = []    \n",
    "        for i in y_test:\n",
    "            foo_list = [0]*10\n",
    "            foo_list[int(i)] = 1\n",
    "            foo_test.append(foo_list)\n",
    "        foo_test = torch.tensor(foo_test).type(torch.float)'''\n",
    "        test_loss = loss_fn(y_logits, y_test.type(torch.long))\n",
    "        \n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "        print(f\"Epoch: {epoch:.2f}, Loss: {loss:.2f}, test_loss: {test_loss:.2f}\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0943)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_model.eval()\n",
    "with torch.inference_mode():\n",
    "    test = hindi_model(X_test)\n",
    "    test_preds = hindi_model.logits_to_preds(test)\n",
    "    \n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Setup Metric\n",
    "torchmetric_accuracy = Accuracy(task=\"multiclass\",num_classes=10)\n",
    "\n",
    "# Calculate accuracy\n",
    "torchmetric_accuracy(test_preds, y_test)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
